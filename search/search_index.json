{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BotsOnRails BotsOnRails is a flexible and lightweight Python library designed to make it easy to create complex workflows involving large language models (LLMs), human input, and arbitrary Python functions. It uses a tree-based orchestration model where each node in the tree represents a task or decision point. Why use BotsOnRails? Easy Integration of LLMs: BotsOnRails makes it simple to integrate LLMs like OpenAI's GPT models into your workflows using libraries like Marvin. Human-in-the-Loop Support: BotsOnRails has first-class support for pausing execution to allow for human review and approval before proceeding. This allows you to build workflows that combine the power of LLMs with human oversight and decision making. Arbitrary Python Logic: In addition to LLMs, BotsOnRails allows you to incorporate arbitrary Python functions as nodes in your workflow. This gives you complete flexibility to build workflows that leverage any Python libraries or custom logic you need. Type-Safe: BotsOnRails uses Python type annotations to validate that data passing between nodes in your workflow matches the expected types. This catches errors before runtime. Dynamic Routing: Routing between nodes can be determined dynamically based on function outputs, allowing you to build workflows that adapt based on the results of each step. Visualization: BotsOnRails can generate visualizations of your workflow DAG to help you understand and debug your workflows. Examples To see BotsOnRails in action, check out these example workflows: Content Moderation : This example shows how to build a content moderation workflow that uses an LLM to classify text content, pausing for human review if the content is flagged as inappropriate. AI Stock Analysis : This more complex example ingests a set of documents about a company's stock and uses an LLM along with the LlamaIndex library to extract key information about the stock, demonstrating more advanced workflow capabilities. AI Agent Orchestration : This example demonstrates an AI agent that uses BotsOnRails to flexibly handle different user intents, leveraging tools like Marvin and custom Python functions. Getting Started To use BotsOnRails in your own project, install it via: pip install BotsOnRails Then check out the Quickstart Guide to learn the key concepts. The Node Syntax Guide dives deeper into how to define nodes and route between them. One key concept to understand is how BotsOnRails handles looping using its For Each Syntax . This allows you to dynamically process each element of an iterable in a type-safe way. BotsOnRails has some Validation Rules to be aware of that enforce the integrity of your workflow definitions. We hope you find BotsOnRails to be a powerful and flexible tool for building LLM workflows! If you have any feedback or questions, please open an issue on our GitHub repo.","title":"Index"},{"location":"#botsonrails","text":"BotsOnRails is a flexible and lightweight Python library designed to make it easy to create complex workflows involving large language models (LLMs), human input, and arbitrary Python functions. It uses a tree-based orchestration model where each node in the tree represents a task or decision point.","title":"BotsOnRails"},{"location":"#why-use-botsonrails","text":"Easy Integration of LLMs: BotsOnRails makes it simple to integrate LLMs like OpenAI's GPT models into your workflows using libraries like Marvin. Human-in-the-Loop Support: BotsOnRails has first-class support for pausing execution to allow for human review and approval before proceeding. This allows you to build workflows that combine the power of LLMs with human oversight and decision making. Arbitrary Python Logic: In addition to LLMs, BotsOnRails allows you to incorporate arbitrary Python functions as nodes in your workflow. This gives you complete flexibility to build workflows that leverage any Python libraries or custom logic you need. Type-Safe: BotsOnRails uses Python type annotations to validate that data passing between nodes in your workflow matches the expected types. This catches errors before runtime. Dynamic Routing: Routing between nodes can be determined dynamically based on function outputs, allowing you to build workflows that adapt based on the results of each step. Visualization: BotsOnRails can generate visualizations of your workflow DAG to help you understand and debug your workflows.","title":"Why use BotsOnRails?"},{"location":"#examples","text":"To see BotsOnRails in action, check out these example workflows: Content Moderation : This example shows how to build a content moderation workflow that uses an LLM to classify text content, pausing for human review if the content is flagged as inappropriate. AI Stock Analysis : This more complex example ingests a set of documents about a company's stock and uses an LLM along with the LlamaIndex library to extract key information about the stock, demonstrating more advanced workflow capabilities. AI Agent Orchestration : This example demonstrates an AI agent that uses BotsOnRails to flexibly handle different user intents, leveraging tools like Marvin and custom Python functions.","title":"Examples"},{"location":"#getting-started","text":"To use BotsOnRails in your own project, install it via: pip install BotsOnRails Then check out the Quickstart Guide to learn the key concepts. The Node Syntax Guide dives deeper into how to define nodes and route between them. One key concept to understand is how BotsOnRails handles looping using its For Each Syntax . This allows you to dynamically process each element of an iterable in a type-safe way. BotsOnRails has some Validation Rules to be aware of that enforce the integrity of your workflow definitions. We hope you find BotsOnRails to be a powerful and flexible tool for building LLM workflows! If you have any feedback or questions, please open an issue on our GitHub repo.","title":"Getting Started"},{"location":"about/","text":"About BotsOnRails Origins BotsOnRails was born out of a frustration with the challenges of building complex workflows involving large language models (LLMs), human interaction, and custom logic. As LLMs like GPT-3 and GPT-4 have become more powerful and accessible, there's been an explosion of interest in building applications that leverage their capabilities. However, building these applications often requires orchestrating a complex dance between AI-generated content, human review and approval, and custom processing logic. Existing workflow orchestration tools, while powerful, often feel overly complex and rigid for these kinds of AI-driven workflows. They require a lot of upfront design and don't easily accommodate the kinds of dynamic, human-in-the-loop workflows that are common when working with LLMs. At the same time, building these workflows from scratch using raw Python code quickly becomes unmanageable. The flow of data and control between different parts of the system becomes hard to follow, and it's easy for subtle bugs and inconsistencies to creep in. BotsOnRails was created to provide a sweet spot between these two extremes. It offers a simple, flexible, and expressive way to define workflows as trees of nodes, where each node represents a single step or decision point. Crucially, it has first-class support for human interaction, allowing you to easily designate any node as a pause point for human review or approval. Why BotsOnRails? So why should you care about BotsOnRails? Here are a few key benefits: Simplicity : BotsOnRails offers a simple and intuitive way to define even complex workflows. The core concepts - nodes, routing, human approval - are easy to grasp, but combine to enable very sophisticated behavior. Flexibility : BotsOnRails imposes very few constraints on what your nodes can do. A node can invoke an LLM, make a database query, call an API, prompt for human input, or run arbitrary Python code. This flexibility means you can use BotsOnRails for a wide variety of use cases. Visibility : BotsOnRails can generate visualizations of your workflow tree, making it easy to see at a glance how data and control flow through your system. This can be invaluable for understanding, debugging, and communicating about your workflows. Resumability : BotsOnRails makes it easy to create workflows that can be paused for human interaction and then seamlessly resumed. This is a game-changer when building human-in-the-loop AI systems, as it means the human can be brought into the loop at any point without disrupting the overall flow. Type Safety : BotsOnRails uses Python's type annotation system to validate the consistency of inputs and outputs between nodes. This can help catch bugs and inconsistencies early, at definition time rather than runtime. Lightweight & Unopinionated : BotsOnRails tries to stay out of your way as much as possible. It doesn't require you to fundamentally change how you write your Python code, and it doesn't impose any heavy runtime dependencies. At its core, BotsOnRails is about empowering developers to build sophisticated AI-driven workflows without sacrificing simplicity, flexibility, or visibility. Whether you're building a content moderation system, a data processing pipeline, or a chatbot, BotsOnRails provides a powerful and expressive foundation. We're excited to see what the community will build with BotsOnRails, and we're committed to evolving the library based on your feedback and needs. If you have ideas, questions, or suggestions, please don't hesitate to open an issue or pull request on our GitHub repo. Happy bot building!","title":"Home"},{"location":"about/#about-botsonrails","text":"","title":"About BotsOnRails"},{"location":"about/#origins","text":"BotsOnRails was born out of a frustration with the challenges of building complex workflows involving large language models (LLMs), human interaction, and custom logic. As LLMs like GPT-3 and GPT-4 have become more powerful and accessible, there's been an explosion of interest in building applications that leverage their capabilities. However, building these applications often requires orchestrating a complex dance between AI-generated content, human review and approval, and custom processing logic. Existing workflow orchestration tools, while powerful, often feel overly complex and rigid for these kinds of AI-driven workflows. They require a lot of upfront design and don't easily accommodate the kinds of dynamic, human-in-the-loop workflows that are common when working with LLMs. At the same time, building these workflows from scratch using raw Python code quickly becomes unmanageable. The flow of data and control between different parts of the system becomes hard to follow, and it's easy for subtle bugs and inconsistencies to creep in. BotsOnRails was created to provide a sweet spot between these two extremes. It offers a simple, flexible, and expressive way to define workflows as trees of nodes, where each node represents a single step or decision point. Crucially, it has first-class support for human interaction, allowing you to easily designate any node as a pause point for human review or approval.","title":"Origins"},{"location":"about/#why-botsonrails","text":"So why should you care about BotsOnRails? Here are a few key benefits: Simplicity : BotsOnRails offers a simple and intuitive way to define even complex workflows. The core concepts - nodes, routing, human approval - are easy to grasp, but combine to enable very sophisticated behavior. Flexibility : BotsOnRails imposes very few constraints on what your nodes can do. A node can invoke an LLM, make a database query, call an API, prompt for human input, or run arbitrary Python code. This flexibility means you can use BotsOnRails for a wide variety of use cases. Visibility : BotsOnRails can generate visualizations of your workflow tree, making it easy to see at a glance how data and control flow through your system. This can be invaluable for understanding, debugging, and communicating about your workflows. Resumability : BotsOnRails makes it easy to create workflows that can be paused for human interaction and then seamlessly resumed. This is a game-changer when building human-in-the-loop AI systems, as it means the human can be brought into the loop at any point without disrupting the overall flow. Type Safety : BotsOnRails uses Python's type annotation system to validate the consistency of inputs and outputs between nodes. This can help catch bugs and inconsistencies early, at definition time rather than runtime. Lightweight & Unopinionated : BotsOnRails tries to stay out of your way as much as possible. It doesn't require you to fundamentally change how you write your Python code, and it doesn't impose any heavy runtime dependencies. At its core, BotsOnRails is about empowering developers to build sophisticated AI-driven workflows without sacrificing simplicity, flexibility, or visibility. Whether you're building a content moderation system, a data processing pipeline, or a chatbot, BotsOnRails provides a powerful and expressive foundation. We're excited to see what the community will build with BotsOnRails, and we're committed to evolving the library based on your feedback and needs. If you have ideas, questions, or suggestions, please don't hesitate to open an issue or pull request on our GitHub repo. Happy bot building!","title":"Why BotsOnRails?"},{"location":"loops/","text":"BotsOnRails For Each Loops A powerful feature of BotsOnRails is the ability to dynamically process each element of an iterable (only lists or tuples ATM) individually using a for each loop. This guide explains how to use this feature. Basic Syntax To use a for each loop, a node must return an iterable output. Then, in the next_step routing specification, use the special tuple syntax (\"FOR_EACH\", \"node_name\") to indicate that each element of the iterable should be processed individually by the specified next node. Here's an example: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] @step(next_step=\"aggregate_results\") def process_item(item: str) -> str: return item.upper() @step() def aggregate_results(item: str) -> str: return item In this example, get_items returns a list of strings. The (\"FOR_EACH\", \"process_item\") routing spec indicates that each string should be passed individually to process_item . The process_item node receives a single string as input (note the type annotation) and processes it, in this case converting it to uppercase. Finally, the results are passed one by one to the aggregate_results node (which would typically aggregate them in some way). Type Safety For each loops in BotsOnRails are type safe. The return type annotation of the node that initiates the loop must be a List or Tuple (or other iterable) and the input type annotation of the processing node must match the element type of the iterable. For example, this is valid: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] @step def process_item(item: str) -> str: return item.upper() But this would raise a type error: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] @step def process_item(item: int) -> int: return item * 2 The processing node expects an int but the for each loop provides a str . Aggregation After processing each element individually, you often want to aggregate the results back together. This is done in an aggregation node. An aggregation node is indicated by the aggregator=True argument to the @step decorator. It must take a single input of the same type outputted by the processing node. While you might expect an aggregator to return a list as a type signature, it should not . Remember, when your IDE is type checking and warning of mismatches, it's looking at the return signatures within the function. We're doing some backend magic to aggregate everything and storing a list of values from each loop during each execution of the for_each loop. The @step(aggregator=True) step is our best attempt (at the moment) to signal to our execution engine that the logic for the loop ends at the aggregator node and should be aggregated. Typically, you're not going to want to do much (if anything) in the aggreagtor other than pass through the received value, which will be aggregated by the ExecutionPath . Here's an example that extends the previous one to aggregate the uppercased strings into a single string: @step(next_step=\"aggregate_results\") def process_item(item: str) -> str: return item.upper() @step(next_step=\"print_list\", aggregator=True) def aggregate_results(items: str) -> str: return items # Note this expects a list whereas the aggregator __function__ provides just a single string. This is due to how we # wrap the functions and perform the `for_each` logic. @step() def print_list(items: List[str]): print(\"Result: \" + \", \".join(items)) The aggregate_results step has been marked as an aggregator via aggregator=True . It outputs a string for each list element. The print_list node takes the List[str] assembled by the aggregator as input and combines them into a single result string. As discussed, the typing is not perfect here (and we're open to suggestions!). The aggreagtor function only returns a single item. The following step's function, however, should expect a list of the types that the aggregator outputs.","title":"Loops"},{"location":"loops/#botsonrails-for-each-loops","text":"A powerful feature of BotsOnRails is the ability to dynamically process each element of an iterable (only lists or tuples ATM) individually using a for each loop. This guide explains how to use this feature.","title":"BotsOnRails For Each Loops"},{"location":"loops/#basic-syntax","text":"To use a for each loop, a node must return an iterable output. Then, in the next_step routing specification, use the special tuple syntax (\"FOR_EACH\", \"node_name\") to indicate that each element of the iterable should be processed individually by the specified next node. Here's an example: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] @step(next_step=\"aggregate_results\") def process_item(item: str) -> str: return item.upper() @step() def aggregate_results(item: str) -> str: return item In this example, get_items returns a list of strings. The (\"FOR_EACH\", \"process_item\") routing spec indicates that each string should be passed individually to process_item . The process_item node receives a single string as input (note the type annotation) and processes it, in this case converting it to uppercase. Finally, the results are passed one by one to the aggregate_results node (which would typically aggregate them in some way).","title":"Basic Syntax"},{"location":"loops/#type-safety","text":"For each loops in BotsOnRails are type safe. The return type annotation of the node that initiates the loop must be a List or Tuple (or other iterable) and the input type annotation of the processing node must match the element type of the iterable. For example, this is valid: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] @step def process_item(item: str) -> str: return item.upper() But this would raise a type error: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] @step def process_item(item: int) -> int: return item * 2 The processing node expects an int but the for each loop provides a str .","title":"Type Safety"},{"location":"loops/#aggregation","text":"After processing each element individually, you often want to aggregate the results back together. This is done in an aggregation node. An aggregation node is indicated by the aggregator=True argument to the @step decorator. It must take a single input of the same type outputted by the processing node. While you might expect an aggregator to return a list as a type signature, it should not . Remember, when your IDE is type checking and warning of mismatches, it's looking at the return signatures within the function. We're doing some backend magic to aggregate everything and storing a list of values from each loop during each execution of the for_each loop. The @step(aggregator=True) step is our best attempt (at the moment) to signal to our execution engine that the logic for the loop ends at the aggregator node and should be aggregated. Typically, you're not going to want to do much (if anything) in the aggreagtor other than pass through the received value, which will be aggregated by the ExecutionPath . Here's an example that extends the previous one to aggregate the uppercased strings into a single string: @step(next_step=\"aggregate_results\") def process_item(item: str) -> str: return item.upper() @step(next_step=\"print_list\", aggregator=True) def aggregate_results(items: str) -> str: return items # Note this expects a list whereas the aggregator __function__ provides just a single string. This is due to how we # wrap the functions and perform the `for_each` logic. @step() def print_list(items: List[str]): print(\"Result: \" + \", \".join(items)) The aggregate_results step has been marked as an aggregator via aggregator=True . It outputs a string for each list element. The print_list node takes the List[str] assembled by the aggregator as input and combines them into a single result string. As discussed, the typing is not perfect here (and we're open to suggestions!). The aggreagtor function only returns a single item. The following step's function, however, should expect a list of the types that the aggregator outputs.","title":"Aggregation"},{"location":"node_syntax/","text":"BotsOnRails Node Syntax This guide dives deeper into the options available when defining workflow nodes in BotsOnRails. Basic Definition As covered in the quickstart, the basic syntax for defining a step first uses the step_decorator_for_path to create a decroator - we typically call it a @step decorator - which can then be used on a Python function: from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(next_step=\"process_data\") def get_data() -> str: return \"Some data\" The @step decorator takes several optional arguments: path_start : Boolean indicating if this is the entry point node for the workflow next_step : Specifies which node(s) to execute after this one (more on this below) wait_for_approval : Boolean indicating if workflow execution should pause after this node for human approval before proceeding. More on this in the guide on resumable workflows . Routing Options The next_step argument provides several options for controlling the flow of execution: Static Routing You can route to a single node by providing the name of the node function as a string: @step(next_step=\"node2\") def node1(): pass Conditional Routing To conditionally route based on the output of a node, provide a dictionary mapping output values to node names: @step(next_step={\"foo\": \"handle_foo\", \"bar\": \"handle_bar\"}) def router() -> str: return \"foo\" Dynamic Routing For even more flexibility, you can provide a function that takes the node output as input and returns the name of the next node: def router_func(output): if output > 10: return \"handle_high\" else: return \"handle_low\" @step(next_step=router_func) def dynamic_router() -> int: return 42 To make full use of functions like type checking and flow visualization be sure to provide a list of all the possible resulting next step names as a list to the func_router_possible_next_step_names argument of the decorator like so: def router_func(output): if output > 10: return \"handle_high\" else: return \"handle_low\" @step(next_step=router_func, func_router_possible_next_step_names=['handle_high', 'handle_low']) def dynamic_router() -> int: return 42 Looping To process each element of an iterable output individually, use the special (\"FOR_EACH\", \"node_name\") syntax: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] See the For Each Guide for more details. Type Annotations BotsOnRails uses Python type annotations to validate the input and output types of nodes. This helps catch type mismatches and ensures the integrity of data flowing through your workflow. Nodes should have type annotations on their input arguments and return value: @step def process_text(text: str) -> str: return text.upper() When possible, use specific types like str , int , List , Dict , etc. rather than the generic Any type. This enables better type checking. Use NoReturn or leave off a return signature where nothing is returned.","title":"Syntax Guide"},{"location":"node_syntax/#botsonrails-node-syntax","text":"This guide dives deeper into the options available when defining workflow nodes in BotsOnRails.","title":"BotsOnRails Node Syntax"},{"location":"node_syntax/#basic-definition","text":"As covered in the quickstart, the basic syntax for defining a step first uses the step_decorator_for_path to create a decroator - we typically call it a @step decorator - which can then be used on a Python function: from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(next_step=\"process_data\") def get_data() -> str: return \"Some data\" The @step decorator takes several optional arguments: path_start : Boolean indicating if this is the entry point node for the workflow next_step : Specifies which node(s) to execute after this one (more on this below) wait_for_approval : Boolean indicating if workflow execution should pause after this node for human approval before proceeding. More on this in the guide on resumable workflows .","title":"Basic Definition"},{"location":"node_syntax/#routing-options","text":"The next_step argument provides several options for controlling the flow of execution:","title":"Routing Options"},{"location":"node_syntax/#static-routing","text":"You can route to a single node by providing the name of the node function as a string: @step(next_step=\"node2\") def node1(): pass","title":"Static Routing"},{"location":"node_syntax/#conditional-routing","text":"To conditionally route based on the output of a node, provide a dictionary mapping output values to node names: @step(next_step={\"foo\": \"handle_foo\", \"bar\": \"handle_bar\"}) def router() -> str: return \"foo\"","title":"Conditional Routing"},{"location":"node_syntax/#dynamic-routing","text":"For even more flexibility, you can provide a function that takes the node output as input and returns the name of the next node: def router_func(output): if output > 10: return \"handle_high\" else: return \"handle_low\" @step(next_step=router_func) def dynamic_router() -> int: return 42 To make full use of functions like type checking and flow visualization be sure to provide a list of all the possible resulting next step names as a list to the func_router_possible_next_step_names argument of the decorator like so: def router_func(output): if output > 10: return \"handle_high\" else: return \"handle_low\" @step(next_step=router_func, func_router_possible_next_step_names=['handle_high', 'handle_low']) def dynamic_router() -> int: return 42","title":"Dynamic Routing"},{"location":"node_syntax/#looping","text":"To process each element of an iterable output individually, use the special (\"FOR_EACH\", \"node_name\") syntax: @step(next_step=(\"FOR_EACH\", \"process_item\")) def get_items() -> List[str]: return [\"foo\", \"bar\", \"baz\"] See the For Each Guide for more details.","title":"Looping"},{"location":"node_syntax/#type-annotations","text":"BotsOnRails uses Python type annotations to validate the input and output types of nodes. This helps catch type mismatches and ensures the integrity of data flowing through your workflow. Nodes should have type annotations on their input arguments and return value: @step def process_text(text: str) -> str: return text.upper() When possible, use specific types like str , int , List , Dict , etc. rather than the generic Any type. This enables better type checking. Use NoReturn or leave off a return signature where nothing is returned.","title":"Type Annotations"},{"location":"quickstart/","text":"BotsOnRails Quickstart This guide will walk you through the key steps and concepts for building a workflow using BotsOnRails. Defining Nodes The key building block in BotsOnRails is a node, which represents a single task or decision point in your workflow. Nodes are defined using normal Python functions, with a few key additions: Use the @node decorator to indicate that a function is a workflow node. At least one node must have path_start=True Add type annotations to the function indicating the expected input and output types Optionally specify a next_step argument indicating which node(s) to execute next Here's an example node definition: # Compile the execution tree from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(next_nodes=\"process_text\", path_start=True) def get_user_input() -> str: return input(\"Please enter some text: \") @step() def process_text(text: str) -> str: return text.upper() path.compile(type_checking=True) path.visualize_via_graphviz() Building a Workflow To build a complete workflow, define an ExecutionPath and add your node functions to it: from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(path_start=True, next_step=\"process_text\") def get_user_input() -> str: return input(\"Please enter some text: \") @step() def process_text(text: str) -> str: return text.upper() Use the path_start=True argument to indicate which step is the entry point for the path. Executing a Workflow To run the workflow, first compile it (you only have to do this once), then call the run method: path.compile() path.run() This will execute the workflow starting from the designated start node. Next Steps That covers the basic concepts! For more advanced topics, check out: The Node Syntax Guide to learn more techniques for defining nodes and routing The For Each Guide to understand BotsOnRails' looping functionality The Validation Rules to understand the guardrails BotsOnRails provides Happy bot building!","title":"Quickstart"},{"location":"quickstart/#botsonrails-quickstart","text":"This guide will walk you through the key steps and concepts for building a workflow using BotsOnRails.","title":"BotsOnRails Quickstart"},{"location":"quickstart/#defining-nodes","text":"The key building block in BotsOnRails is a node, which represents a single task or decision point in your workflow. Nodes are defined using normal Python functions, with a few key additions: Use the @node decorator to indicate that a function is a workflow node. At least one node must have path_start=True Add type annotations to the function indicating the expected input and output types Optionally specify a next_step argument indicating which node(s) to execute next Here's an example node definition: # Compile the execution tree from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(next_nodes=\"process_text\", path_start=True) def get_user_input() -> str: return input(\"Please enter some text: \") @step() def process_text(text: str) -> str: return text.upper() path.compile(type_checking=True) path.visualize_via_graphviz()","title":"Defining Nodes"},{"location":"quickstart/#building-a-workflow","text":"To build a complete workflow, define an ExecutionPath and add your node functions to it: from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(path_start=True, next_step=\"process_text\") def get_user_input() -> str: return input(\"Please enter some text: \") @step() def process_text(text: str) -> str: return text.upper() Use the path_start=True argument to indicate which step is the entry point for the path.","title":"Building a Workflow"},{"location":"quickstart/#executing-a-workflow","text":"To run the workflow, first compile it (you only have to do this once), then call the run method: path.compile() path.run() This will execute the workflow starting from the designated start node.","title":"Executing a Workflow"},{"location":"quickstart/#next-steps","text":"That covers the basic concepts! For more advanced topics, check out: The Node Syntax Guide to learn more techniques for defining nodes and routing The For Each Guide to understand BotsOnRails' looping functionality The Validation Rules to understand the guardrails BotsOnRails provides Happy bot building!","title":"Next Steps"},{"location":"resumable_workflows/","text":"Resumable and Human-Approvable Workflows in BotsOnRails One of the key features of BotsOnRails is the ability to create workflows that can be paused, reviewed by a human, and then resumed. This is particularly useful when you need human judgment or approval at certain points in your workflow. Marking a Node for Human Approval To mark a node as requiring human approval before the workflow can proceed, use the wait_for_approval=True argument to the @step decorator: from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(wait_for_approval=True) def human_review(text: str) -> bool: print(f\"Please review the following text: {text}\") return input(\"Approve? (y/n): \").lower() == \"y\" When the workflow reaches this node, it will pause execution and wait for human interaction. The node function should prompt the user for input and return a value indicating whether to proceed or not. Resuming a Workflow When a workflow is paused at a human approval node, you can resume it by calling the run_from_step method on the ExecutionPath : result = path.run(initial_data) if result == SpecialTypes.EXECUTION_HALTED: print(\"Workflow paused for human approval\") approve = input(\"Proceed? (y/n): \").lower() == \"y\" if approve: path.run_from_step( halted_node_name, prev_execution_state=tree.model_dump(), has_approval=True ) else: print(\"Workflow cancelled by user\") The run method will return a special value SpecialTypes.EXECUTION_HALTED if the workflow is paused at a human approval node. To resume, you first need to get the name of the node where execution is halted. You can find this in the locked_at_step_name attribute of the ExecutionPath . Then, call run_from_step , passing: - The name of the node to resume from - The previous execution state, obtained by calling model_dump() on the ExecutionPath - has_approval=True to indicate that the human has approved proceeding The workflow will then resume from the approval node. Detailed Example Here's a more detailed example of a content moderation workflow that uses human approval: from BotsOnRails import ExecutionPath, step_decorator_for_path, SpecialTypes path = ExecutionPath() step = step_decorator_for_path(path) @step(path_start=True, next_step={\"flagged\": \"human_review\", \"clean\": \"publish\"}) def analyze_content(text: str, **kwargs) -> str: if \"spam\" in text: return \"flagged\" else: return \"clean\" @step(wait_for_approval=True, next_step={\"approve\": \"publish\", \"reject\": \"end\"}) def human_review(text: str, **kwargs) -> str: # You can access data from other nodes using the runtime_args property in the kwargs orig_input = kwargs['runtime_args']['input'][0] print(f\"Please review the following content: {orig_input}\") # We set this is a default return type, but we can override this when we resume the workflow return \"reject\" @step() def publish(text: str, **kwargs): print(f\"Publishing: {text}\") @step() def end(**kwargs): print(\"Content rejected\") path.compile() while True: text = input(\"Enter some text to moderate (or 'quit'): \") if text == \"quit\": break result = path.run(text) if result == SpecialTypes.EXECUTION_HALTED: halted_node = path.locked_at_step_name print(f\"Workflow paused at {halted_node}\") approve = input(\"Proceed? (y/n): \").lower() == \"y\" if approve: path.run_from_step( halted_node, prev_execution_state=path.model_dump(), has_approval=True, override_output=\"approve\" ) else: path.run_from_step( halted_node, prev_execution_state=path.model_dump(), has_approval=True, override_output=\"reject\" ) This workflow first analyzes the input text. If it's flagged as potentially inappropriate, it routes to a human_review node for approval. This node is marked with wait_for_approval=True , so execution will pause here. The main loop checks the result of tree.run() . If it's EXECUTION_HALTED , it prompts the user to approve or reject the content. If approved, it resumes the workflow from the human_review node with override_output=\"approve\" , which will cause the workflow to proceed to the publish node. If rejected, it resumes with override_output=\"reject\" , which will route to the end node instead. This demonstrates how you can build workflows that flexibly incorporate human judgment and easily resume after human interaction. The wait_for_approval mechanism allows you to designate any node as a pause point, and run_from_step allows you to resume from that point once human input is provided. You can also see how the execution state could be easily persisted to disk and then resumed later... the ExecutionPath obj instance is a Pydantic model, so we can dump the model out to disk, serialize it, store it, and return to execution at any arbitrary point in time.","title":"Resume"},{"location":"resumable_workflows/#resumable-and-human-approvable-workflows-in-botsonrails","text":"One of the key features of BotsOnRails is the ability to create workflows that can be paused, reviewed by a human, and then resumed. This is particularly useful when you need human judgment or approval at certain points in your workflow.","title":"Resumable and Human-Approvable Workflows in BotsOnRails"},{"location":"resumable_workflows/#marking-a-node-for-human-approval","text":"To mark a node as requiring human approval before the workflow can proceed, use the wait_for_approval=True argument to the @step decorator: from BotsOnRails import ExecutionPath, step_decorator_for_path path = ExecutionPath() step = step_decorator_for_path(path) @step(wait_for_approval=True) def human_review(text: str) -> bool: print(f\"Please review the following text: {text}\") return input(\"Approve? (y/n): \").lower() == \"y\" When the workflow reaches this node, it will pause execution and wait for human interaction. The node function should prompt the user for input and return a value indicating whether to proceed or not.","title":"Marking a Node for Human Approval"},{"location":"resumable_workflows/#resuming-a-workflow","text":"When a workflow is paused at a human approval node, you can resume it by calling the run_from_step method on the ExecutionPath : result = path.run(initial_data) if result == SpecialTypes.EXECUTION_HALTED: print(\"Workflow paused for human approval\") approve = input(\"Proceed? (y/n): \").lower() == \"y\" if approve: path.run_from_step( halted_node_name, prev_execution_state=tree.model_dump(), has_approval=True ) else: print(\"Workflow cancelled by user\") The run method will return a special value SpecialTypes.EXECUTION_HALTED if the workflow is paused at a human approval node. To resume, you first need to get the name of the node where execution is halted. You can find this in the locked_at_step_name attribute of the ExecutionPath . Then, call run_from_step , passing: - The name of the node to resume from - The previous execution state, obtained by calling model_dump() on the ExecutionPath - has_approval=True to indicate that the human has approved proceeding The workflow will then resume from the approval node.","title":"Resuming a Workflow"},{"location":"resumable_workflows/#detailed-example","text":"Here's a more detailed example of a content moderation workflow that uses human approval: from BotsOnRails import ExecutionPath, step_decorator_for_path, SpecialTypes path = ExecutionPath() step = step_decorator_for_path(path) @step(path_start=True, next_step={\"flagged\": \"human_review\", \"clean\": \"publish\"}) def analyze_content(text: str, **kwargs) -> str: if \"spam\" in text: return \"flagged\" else: return \"clean\" @step(wait_for_approval=True, next_step={\"approve\": \"publish\", \"reject\": \"end\"}) def human_review(text: str, **kwargs) -> str: # You can access data from other nodes using the runtime_args property in the kwargs orig_input = kwargs['runtime_args']['input'][0] print(f\"Please review the following content: {orig_input}\") # We set this is a default return type, but we can override this when we resume the workflow return \"reject\" @step() def publish(text: str, **kwargs): print(f\"Publishing: {text}\") @step() def end(**kwargs): print(\"Content rejected\") path.compile() while True: text = input(\"Enter some text to moderate (or 'quit'): \") if text == \"quit\": break result = path.run(text) if result == SpecialTypes.EXECUTION_HALTED: halted_node = path.locked_at_step_name print(f\"Workflow paused at {halted_node}\") approve = input(\"Proceed? (y/n): \").lower() == \"y\" if approve: path.run_from_step( halted_node, prev_execution_state=path.model_dump(), has_approval=True, override_output=\"approve\" ) else: path.run_from_step( halted_node, prev_execution_state=path.model_dump(), has_approval=True, override_output=\"reject\" ) This workflow first analyzes the input text. If it's flagged as potentially inappropriate, it routes to a human_review node for approval. This node is marked with wait_for_approval=True , so execution will pause here. The main loop checks the result of tree.run() . If it's EXECUTION_HALTED , it prompts the user to approve or reject the content. If approved, it resumes the workflow from the human_review node with override_output=\"approve\" , which will cause the workflow to proceed to the publish node. If rejected, it resumes with override_output=\"reject\" , which will route to the end node instead. This demonstrates how you can build workflows that flexibly incorporate human judgment and easily resume after human interaction. The wait_for_approval mechanism allows you to designate any node as a pause point, and run_from_step allows you to resume from that point once human input is provided. You can also see how the execution state could be easily persisted to disk and then resumed later... the ExecutionPath obj instance is a Pydantic model, so we can dump the model out to disk, serialize it, store it, and return to execution at any arbitrary point in time.","title":"Detailed Example"},{"location":"validation/","text":"BotsOnRails Validation Rules To help ensure the integrity of your workflows, BotsOnRails enforces certain validation rules. This document outlines the key rules to be aware of. No Nested Cycles BotsOnRails does not allow nested cycles in the workflow graph. A nested cycle means a cycle within a cycle. For example, this is not allowed: @step(next_step=\"node2\") def node1(): pass @step(next_step=\"node3\") def node2(): pass @step(next_step=\"node1\") def node3(): pass This creates a cycle node1 -> node2 -> node3 -> node1 . Cycles are detected when you call compile() on your ExecutionTree . A ValueError will be raised if a nested cycle is found. Return Type Consistency The return type annotation of a node must match the input type annotation of any nodes it routes to. For example, this is valid: @step(next_step=\"node2\") def node1() -> int: return 42 @step def node2(x: int): print(x) But this would raise an error: @step(next_step=\"node2\") def node1() -> int: return 42 @step def node2(x: str): print(x) The return type of node1 is int but node2 expects a str input.","title":"Type Checking"},{"location":"validation/#botsonrails-validation-rules","text":"To help ensure the integrity of your workflows, BotsOnRails enforces certain validation rules. This document outlines the key rules to be aware of.","title":"BotsOnRails Validation Rules"},{"location":"validation/#no-nested-cycles","text":"BotsOnRails does not allow nested cycles in the workflow graph. A nested cycle means a cycle within a cycle. For example, this is not allowed: @step(next_step=\"node2\") def node1(): pass @step(next_step=\"node3\") def node2(): pass @step(next_step=\"node1\") def node3(): pass This creates a cycle node1 -> node2 -> node3 -> node1 . Cycles are detected when you call compile() on your ExecutionTree . A ValueError will be raised if a nested cycle is found.","title":"No Nested Cycles"},{"location":"validation/#return-type-consistency","text":"The return type annotation of a node must match the input type annotation of any nodes it routes to. For example, this is valid: @step(next_step=\"node2\") def node1() -> int: return 42 @step def node2(x: int): print(x) But this would raise an error: @step(next_step=\"node2\") def node1() -> int: return 42 @step def node2(x: str): print(x) The return type of node1 is int but node2 expects a str input.","title":"Return Type Consistency"}]}